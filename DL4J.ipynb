{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Running Java in Data Science experience!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "There are 2 ways of running Java in Data Science experience. One way is to run it locally by passing the dependencies and working file and the other is to ship the content to the running master in Spark. We will try out both ways. NOTE:This notebook is the learnings I got from the course \"Applied AI with Deep Learning\" and thus would be very basic as I am trying my hands on with DL4J the first time! :)\n\nThis link to the jar file that has Java code to execute and contains dependencies. We need to ship it, in both the ways of working with Java and also need to load the text file we need to work with!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1st way : Running Java locally!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!wget https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-01-14 07:03:36--  https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nResolving github.com (github.com)... 192.30.253.112, 192.30.253.113\nConnecting to github.com (github.com)|192.30.253.112|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190114T130336Z&X-Amz-Expires=300&X-Amz-Signature=73ef48620391c71bbf655a42faf30d654bf07fd300f0550d00defb755767cdf8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream [following]\n--2019-01-14 07:03:36--  https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190114T130336Z&X-Amz-Expires=300&X-Amz-Signature=73ef48620391c71bbf655a42faf30d654bf07fd300f0550d00defb755767cdf8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream\nResolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.136.252\nConnecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.136.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 445763450 (425M) [application/octet-stream]\nSaving to: \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019\n\n100%[======================================>] 445,763,450 10.2MB/s   in 30s    \n\n2019-01-14 07:04:06 (14.3 MB/s) - \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019 saved [445763450/445763450]\n\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "!wget https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-01-14 07:04:07--  https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2850 (2.8K) [text/plain]\nSaving to: \u2018iris.txt\u2019\n\n100%[======================================>] 2,850       --.-K/s   in 0s      \n\n2019-01-14 07:04:08 (20.0 MB/s) - \u2018iris.txt\u2019 saved [2850/2850]\n\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "!java -version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "java version \"1.8.0_191\"\r\nJava(TM) SE Runtime Environment (build 8.0.5.25 - pxa6480sr5fp25-20181030_01(SR5 FP25))\r\nIBM J9 VM (build 2.9, JRE 1.8.0 Linux amd64-64-Bit Compressed References 20181029_400846 (JIT enabled, AOT enabled)\r\nOpenJ9   - c5c78da\r\nOMR      - 3d5ac33\r\nIBM      - 8c1bdc2)\r\nJCL - 20181022_01 based on Oracle jdk8u191-b26\r\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "!java -cp dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar skymind.dsx.IrisClassifier", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n38 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dnsns.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/traceformat.jar\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmldsigprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/CmpCrmf.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/nashorn.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlencprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmpkcs11impl.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjcefips.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/IBMSecureRandom.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/localedata.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfj.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/xmlencfw.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjceplus.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jverbs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/cldrdata.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmsaslprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfjview.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/zipfs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlcrypto.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmcmsprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmkeycert.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/healthcenter.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/gskikm.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjceprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jaccess.jar\n884 [main] INFO org.reflections.Reflections  - Reflections took 842 ms to scan 26 urls, producing 130205 keys and 144077 values \n1816 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n1818 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n2147 [main] INFO org.reflections.Reflections  - Reflections took 329 ms to scan 1 urls, producing 31 keys and 227 values \n2905 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n2909 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n2909 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [0.5GB];\n2909 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n2930 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n3414 [main] INFO org.reflections.Reflections  - Reflections took 483 ms to scan 1 urls, producing 421 keys and 1666 values \n3474 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n3693 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n10395 [main] INFO org.reflections.Reflections  - Reflections took 6701 ms to scan 1 urls, producing 6280 keys and 43014 values \n10460 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10460 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10460 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n10461 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10461 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n10465 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10465 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10465 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n10465 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n10465 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n10509 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n10578 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4449257209642907\n11485 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3325836280533762\n12146 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.14426999838254637\n12800 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.08850919359454747\n13223 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.06588535008334481\n13643 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.05324888046154947\n14186 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.04498869953810123\n14534 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.039030991711477336\n14922 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.034441277946930325\n15316 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.03074479464604178\n15950 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 20 times\nExamples labeled as 1 classified by model as 1: 16 times\nExamples labeled as 2 classified by model as 1: 2 times\nExamples labeled as 2 classified by model as 2: 15 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9623\n Precision:       0.9630\n Recall:          0.9608\n F1 Score:        0.9596\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "We notice that the model is iterated appx 1000 times and the score is decreasing, which basically represents the error decreasing at each iteration. The accuracy, precision recall and F1 score is given at the end of training.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2nd way : Submitting to Spark", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We will initialize the submit by passing the location of spark-submit executables, which is stored in the variable SPARK_HOMES. SPark submit allows us to specify which class we need to execute. Master is the variable pointing to the current Spark Master and pass the text file. In other words,\nShip the jar up to the spark Master, execute the class using the txt file.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!$SPARK_HOME/bin/spark-submit \\  \n--class skymind.dsx.IrisClassifier \\\n--master $MASTER \\\n--files iris.txt \\\ndl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.3-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v37/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v37/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n19/01/14 07:26:09 INFO linalg.factory.Nd4jBackend: Loaded [CpuBackend] backend\n0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n19/01/14 07:26:09 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n427 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n19/01/14 07:26:09 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n429 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:09 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n652 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:09 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n653 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n798 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n799 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n851 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n852 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1148 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1150 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1409 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1411 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1412 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1413 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1452 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:10 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1453 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:11 INFO org.reflections.Reflections: Reflections took 2102 ms to scan 466 urls, producing 257189 keys and 341974 values \n2149 [main] INFO org.reflections.Reflections  - Reflections took 2102 ms to scan 466 urls, producing 257189 keys and 341974 values \n19/01/14 07:26:11 INFO nd4j.nativeblas.NativeOpsHolder: Number of threads used for NativeOps: 12\n2649 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n19/01/14 07:26:12 INFO org.reflections.Reflections: Reflections took 366 ms to scan 1 urls, producing 31 keys and 227 values \n3019 [main] INFO org.reflections.Reflections  - Reflections took 366 ms to scan 1 urls, producing 31 keys and 227 values \n19/01/14 07:26:12 INFO nd4j.nativeblas.Nd4jBlas: Number of threads used for BLAS: 12\n3340 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n19/01/14 07:26:12 INFO ops.executioner.DefaultOpExecutioner: Backend used: [CPU]; OS: [Linux]\n3342 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n19/01/14 07:26:12 INFO ops.executioner.DefaultOpExecutioner: Cores: [48]; Memory: [1.5GB];\n3343 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [1.5GB];\n19/01/14 07:26:12 INFO ops.executioner.DefaultOpExecutioner: Blas vendor: [OPENBLAS]\n3343 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n19/01/14 07:26:13 INFO org.reflections.Reflections: Reflections took 391 ms to scan 1 urls, producing 421 keys and 1666 values \n3855 [main] INFO org.reflections.Reflections  - Reflections took 391 ms to scan 1 urls, producing 421 keys and 1666 values \n19/01/14 07:26:13 INFO skymind.dsx.IrisClassifier: Build model....\n3920 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n19/01/14 07:26:15 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n6643 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n19/01/14 07:26:15 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n6644 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:19 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n9697 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:19 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n9698 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:20 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n11603 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:20 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n11604 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:21 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n12523 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:21 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n12524 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:26 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n17444 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:26 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n17445 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/sec9-e7fbc73d54603b-96160961875a/data/libs/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:30 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21264 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:30 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21266 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:30 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21267 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:30 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21268 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:31 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21729 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/01/14 07:26:31 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n21730 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:508)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "19/01/14 07:26:40 INFO org.reflections.Reflections: Reflections took 26897 ms to scan 441 urls, producing 17907 keys and 115348 values \n31131 [main] INFO org.reflections.Reflections  - Reflections took 26897 ms to scan 441 urls, producing 17907 keys and 115348 values \n19/01/14 07:26:40 INFO nn.multilayer.MultiLayerNetwork: Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n31278 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n19/01/14 07:26:40 INFO optimize.listeners.ScoreIterationListener: Score at iteration 0 is 1.4602809392813816\n31376 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4602809392813816\n19/01/14 07:26:41 INFO optimize.listeners.ScoreIterationListener: Score at iteration 100 is 0.3809712064929076\n31986 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3809712064929076\n19/01/14 07:26:41 INFO optimize.listeners.ScoreIterationListener: Score at iteration 200 is 0.1654802283255915\n32651 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.1654802283255915\n19/01/14 07:26:42 INFO optimize.listeners.ScoreIterationListener: Score at iteration 300 is 0.10785507383493725\n33287 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.10785507383493725\n19/01/14 07:26:43 INFO optimize.listeners.ScoreIterationListener: Score at iteration 400 is 0.08589342702974447\n33780 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.08589342702974447\n19/01/14 07:26:43 INFO optimize.listeners.ScoreIterationListener: Score at iteration 500 is 0.07528885036543097\n34178 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.07528885036543097\n19/01/14 07:26:43 INFO optimize.listeners.ScoreIterationListener: Score at iteration 600 is 0.06937171731229337\n34586 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.06937171731229337\n19/01/14 07:26:44 INFO optimize.listeners.ScoreIterationListener: Score at iteration 700 is 0.06569055465418026\n34973 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.06569055465418026\n19/01/14 07:26:44 INFO optimize.listeners.ScoreIterationListener: Score at iteration 800 is 0.06320212416164668\n35347 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.06320212416164668\n19/01/14 07:26:45 INFO optimize.listeners.ScoreIterationListener: Score at iteration 900 is 0.061407452547797996\n35697 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.061407452547797996\n19/01/14 07:26:45 INFO skymind.dsx.IrisClassifier: \nExamples labeled as 0 classified by model as 0: 20 times\nExamples labeled as 1 classified by model as 1: 12 times\nExamples labeled as 2 classified by model as 2: 21 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        1.0000\n Precision:       1.0000\n Recall:          1.0000\n F1 Score:        1.0000\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n36227 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 20 times\nExamples labeled as 1 classified by model as 1: 12 times\nExamples labeled as 2 classified by model as 2: 21 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        1.0000\n Precision:       1.0000\n Recall:          1.0000\n F1 Score:        1.0000\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "We notice obtaining such high accuracy precision recall and F1 score, though this is not always the case as the class I took, the instructor got the accuracy lower than that obained earlier", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}