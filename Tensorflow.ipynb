{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt "
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "batch_xs, batch_ys = mnist.train.next_batch(1)"
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n"
                }, 
                {
                    "execution_count": 33, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<matplotlib.image.AxesImage at 0x2b3b0d870390>"
                    }, 
                    "output_type": "execute_result"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x2b3b0d489c50>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# reshape it back to 28x28\nbatch_xs = batch_xs.reshape([28,28])\nplt.gray()\nprint (batch_ys)\nplt.imshow(batch_xs)"
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# starting tensorflow code by using placeholder : a variable where we assign value at the later stage, this allows us to build computation graph withput needing hte actual data\n\nx = tf.placeholder(tf.float32, [None, 784]) # placeholders are used to store data values\nW = tf.Variable(tf.zeros([784,10])) #whereas Variable is the one tensorflow tweaks during training\nb = tf.Variable(tf.zeros([10]))\ny_ = tf.nn.softmax(tf.matmul(x,W) + b)"
        }, 
        {
            "execution_count": 35, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y = tf.placeholder(tf.float32, [None,10])"
        }, 
        {
            "execution_count": 36, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_), reduction_indices = [1])) #reduction indices tells the 10 columns to be reduced to 1 value\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) #Forward and backprop all taken care!"
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sess = tf.InteractiveSession() # deploys on CPU or GPU..."
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "tf.global_variables_initializer().run()  #This initializes the variables which have only been computationally declared\nfor _ in range(1000):\n    batchxs, batchys = mnist.train.next_batch(100) #Taking batch of 100 images\n    sess.run(train_step, feed_dict = {x: batchxs, y: batchys})  #create session object and use feed_dict to match the values to the placeholders created earlier\n"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "correct_pred = tf.equal(tf.argmax(y_,1), tf.argmax(y, 1)) #equal compares the values, argmax returns the single value from one hot vector"
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))  #since correct_pred is boolean value, we cast it to float "
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.9175\n"
                }
            ], 
            "source": "print(sess.run(accuracy, feed_dict={x : mnist.test.images, y : mnist.test.labels}))  #to display the ouptut for anythin in tensor, we need to run the session"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}